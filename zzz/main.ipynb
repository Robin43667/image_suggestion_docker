{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REQUIREMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import exifread\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from difflib import SequenceMatcher\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "from IPython.display import display, Image\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from collections import Counter\n",
    "from matplotlib.patches import Rectangle\n",
    "from wordcloud import WordCloud\n",
    "import seaborn as sns\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TELECHARGER DATASET WIKIDATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import requests\n",
    "import random\n",
    "\n",
    "def telecharger_images_wikidata(requete_sparql, nombre_images, dossier_telechargement, prefixe):\n",
    "    url_wikidata = \"https://query.wikidata.org/sparql\"\n",
    "    params = {\n",
    "        \"query\": requete_sparql,\n",
    "        \"format\": \"json\",\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        reponse = requests.get(url_wikidata, params=params)\n",
    "        reponse.raise_for_status()\n",
    "\n",
    "        donnees = reponse.json()\n",
    "        urls_images = [result[\"image\"][\"value\"] for result in donnees[\"results\"][\"bindings\"]]\n",
    "        urls_images_aleatoires = random.sample(urls_images, min(nombre_images, len(urls_images)))\n",
    "\n",
    "        os.makedirs(dossier_telechargement, exist_ok=True)\n",
    "\n",
    "        for i, url_image in enumerate(urls_images_aleatoires):\n",
    "            try:\n",
    "                headers = {'User-Agent': 'MonProgrammePython/1.0 (test@example.com)'}\n",
    "                reponse_image = requests.get(url_image, stream=True, headers=headers)\n",
    "                reponse_image.raise_for_status()\n",
    "\n",
    "                nom_fichier = os.path.join(dossier_telechargement, f\"{prefixe}_{i+1}.jpg\")\n",
    "                with open(nom_fichier, \"wb\") as fichier:\n",
    "                    for chunk in reponse_image.iter_content(chunk_size=8192):\n",
    "                        fichier.write(chunk)\n",
    "\n",
    "                print(f\"Image {i+1} téléchargée : {nom_fichier}\")\n",
    "\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Erreur lors du téléchargement de l'image {i+1} : {e}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Erreur lors de la requête Wikidata : {e}\")\n",
    "\n",
    "\n",
    "requete_sparql_nebuleuses = \"\"\"\n",
    "SELECT ?image\n",
    "WHERE {\n",
    "  ?nebuleuse wdt:P31/wdt:P279* wd:Q204194 .\n",
    "  ?nebuleuse wdt:P18 ?image .\n",
    "}\n",
    "LIMIT 35\n",
    "\"\"\"\n",
    "\n",
    "requete_sparql_glaciers = \"\"\"\n",
    "SELECT ?image\n",
    "WHERE {\n",
    "  ?glacier wdt:P31/wdt:P279* wd:Q35666 .\n",
    "  ?glacier wdt:P18 ?image .\n",
    "}\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "requete_sparql_montagne = \"\"\"\n",
    "SELECT ?montagne ?montagneLabel ?image ?altitude ?coordonnees ?paysLabel\n",
    "WHERE {\n",
    "  ?montagne wdt:P31/wdt:P279* wd:Q8502. \n",
    "  ?montagne wdt:P18 ?image . \n",
    "  OPTIONAL { ?montagne wdt:P2044 ?altitude . } \n",
    "  OPTIONAL { ?montagne wdt:P625 ?coordonnees . } \n",
    "  OPTIONAL { ?montagne wdt:P17 ?pays . } \n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\" . } \n",
    "}\n",
    "LIMIT 35\n",
    "\"\"\"\n",
    "\n",
    "requete_sparql_peinture = \"\"\"\n",
    "SELECT ?peinture ?peintureLabel ?image ?artisteLabel ?dateCreation\n",
    "WHERE {\n",
    "  ?peinture wdt:P31 wd:Q3305213 .\n",
    "  ?peinture wdt:P18 ?image .\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\" . }\n",
    "}\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "DOSSIER_TELECHARGEMENT = \"dataset\"\n",
    "\n",
    "# Vérifie si le dossier existe et s'il est vide\n",
    "if not os.path.exists(DOSSIER_TELECHARGEMENT) or not os.listdir(DOSSIER_TELECHARGEMENT):\n",
    "    telecharger_images_wikidata(requete_sparql_nebuleuses, nombre_images=35, dossier_telechargement=DOSSIER_TELECHARGEMENT, prefixe=\"nebuleuse\")\n",
    "    telecharger_images_wikidata(requete_sparql_glaciers, nombre_images=20, dossier_telechargement=DOSSIER_TELECHARGEMENT, prefixe=\"glacier\")\n",
    "    telecharger_images_wikidata(requete_sparql_montagne, nombre_images=35, dossier_telechargement=DOSSIER_TELECHARGEMENT, prefixe=\"montagne\")\n",
    "    telecharger_images_wikidata(requete_sparql_peinture, nombre_images=20, dossier_telechargement=DOSSIER_TELECHARGEMENT, prefixe=\"peinture\")\n",
    "else :\n",
    "  print(f\"Le dossier '{DOSSIER_TELECHARGEMENT}' n'est pas vide. Téléchargement ignoré.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  GENERER JSON MATADATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"1\"\n",
    "\n",
    "def get_dominant_colors(image_path, k=5):\n",
    "    try:\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(f\"Image introuvable : {image_path}\")\n",
    "        \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (100, 100), interpolation=cv2.INTER_LINEAR)\n",
    "        image = image.reshape((-1, 3))\n",
    "        \n",
    "        kmeans = KMeans(n_clusters=k, random_state=0, n_init=5)\n",
    "        kmeans.fit(image)\n",
    "        \n",
    "        colors = kmeans.cluster_centers_.astype(int)\n",
    "        return [(int(c[0]), int(c[1]), int(c[2])) for c in colors]\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur analyse couleur {image_path} : {e}\")\n",
    "        return [(0, 0, 0)] * k\n",
    "\n",
    "def generate_tags(metadata):\n",
    "    tags = set()\n",
    "    if metadata.get(\"width\") and metadata.get(\"height\"):\n",
    "        tags.add(\"#paysage\" if metadata[\"width\"] > metadata[\"height\"] else \"#portrait\")\n",
    "    if metadata.get(\"format\"):\n",
    "        tags.add(f\"#{metadata['format'].lower()}\")\n",
    "    if \"Make\" in metadata.get(\"exifs\", {}):\n",
    "        tags.add(f\"#{metadata['exifs']['Make'].lower()}\")\n",
    "    return list(tags)\n",
    "\n",
    "def analyser_images(dossier_telechargement, fichier_sortie):\n",
    "    resultats = []\n",
    "\n",
    "    for fichier in os.listdir(dossier_telechargement):\n",
    "        chemin_complet = os.path.join(dossier_telechargement, fichier)\n",
    "\n",
    "        if os.path.isfile(chemin_complet) and fichier.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            metadata = {\n",
    "                'nom_fichier': fichier,\n",
    "                'extension': os.path.splitext(fichier)[1].lower(),\n",
    "                'format': '',\n",
    "                'width': None,\n",
    "                'height': None,\n",
    "                'moyenne_couleur_rgb': [(0, 0, 0)] * 5,\n",
    "                'exifs': {},\n",
    "                'tags': []\n",
    "            }\n",
    "\n",
    "            # Lecture des dimensions et du format\n",
    "            try:\n",
    "                with Image.open(chemin_complet) as img:\n",
    "                    metadata['width'], metadata['height'] = img.size\n",
    "                    metadata['format'] = img.format\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur lors de l'ouverture de l'image {fichier} avec PIL : {e}\")\n",
    "\n",
    "            # Lecture des EXIFs\n",
    "            try:\n",
    "                with open(chemin_complet, 'rb') as f:\n",
    "                    tags = exifread.process_file(f)\n",
    "                    for tag in ['Image Make', 'Image Model', 'EXIF DateTimeOriginal']:\n",
    "                        if tag in tags:\n",
    "                            tag_key = tag.split()[-1]  # Simplifie : 'Make', 'Model', 'DateTimeOriginal'\n",
    "                            metadata['exifs'][tag_key] = str(tags[tag])\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur lors de la lecture des métadonnées EXIF de {fichier} : {e}\")\n",
    "\n",
    "            # Couleurs dominantes\n",
    "            metadata['moyenne_couleur_rgb'] = get_dominant_colors(chemin_complet, k=5)\n",
    "\n",
    "            # Tags\n",
    "            metadata['tags'] = generate_tags(metadata)\n",
    "\n",
    "            resultats.append(metadata)\n",
    "\n",
    "    # Écriture du fichier JSON\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(fichier_sortie), exist_ok=True)\n",
    "        with open(fichier_sortie, 'w', encoding='utf-8') as f:\n",
    "            json.dump(resultats, f, indent=4, ensure_ascii=False)\n",
    "        print(f\"Métadonnées enrichies sauvegardées dans {fichier_sortie}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'écriture du fichier JSON : {e}\")\n",
    "\n",
    "DOSSIER_TELECHARGEMENT = \"dataset\"\n",
    "FICHIER_SORTIE = \"export/resultats_metadonnees.json\"\n",
    "\n",
    "analyser_images(DOSSIER_TELECHARGEMENT, FICHIER_SORTIE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "def ask_user_preference(image_path):\n",
    "    display(Image(filename=image_path))  \n",
    "    response = input(f\"Aimez-vous cette image {os.path.basename(image_path)} ? (oui/non): \").strip().lower()\n",
    "    return response == 'oui'\n",
    "\n",
    "user_name = input(\"Entrez votre nom: \").strip()\n",
    "\n",
    "dataset_folder = \"dataset\"\n",
    "json_file = \"export/user_preferences.json\"\n",
    "\n",
    "if os.path.exists(json_file):\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        user_data = json.load(f)\n",
    "else:\n",
    "    user_data = {}\n",
    "\n",
    "if user_name not in user_data:\n",
    "    user_data[user_name] = []\n",
    "\n",
    "all_images = [os.path.join(dataset_folder, f) for f in os.listdir(dataset_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "chosen_images = random.sample(all_images, 10)\n",
    "\n",
    "for image_path in chosen_images:\n",
    "    if ask_user_preference(image_path):\n",
    "        user_data[user_name].append(os.path.basename(image_path))\n",
    "\n",
    "with open(json_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(user_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"Vos préférences ont été sauvegardées dans {json_file}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRAPHIQUES PREFERENCES UTILISATEUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyser_preferences(metadata_file, preferences_file):\n",
    "    if not os.path.exists(preferences_file):\n",
    "        print(\"Fichier user_preferences.json introuvable.\")\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(metadata_file):\n",
    "        print(\"Fichier resultats_metadonnees.json introuvable.\")\n",
    "        return\n",
    "\n",
    "    with open(preferences_file, 'r', encoding='utf-8') as f:\n",
    "        preferences_data = json.load(f)\n",
    "\n",
    "    with open(metadata_file, 'r', encoding='utf-8') as f:\n",
    "        metadata_list = json.load(f)\n",
    "\n",
    "    user_syntheses = {}\n",
    "\n",
    "    # Traitement des préférences pour chaque utilisateur\n",
    "    for user_name, liked_images in preferences_data.items():\n",
    "        print(f\"Analyzing preferences for {user_name}...\")\n",
    "        \n",
    "        liked_metadata = [m for m in metadata_list if m[\"nom_fichier\"] in liked_images]\n",
    "\n",
    "        if not liked_metadata:\n",
    "            print(f\"Aucun métadonnée trouvée pour l'utilisateur {user_name}.\")\n",
    "            continue\n",
    "\n",
    "        # Analyse des préférences\n",
    "        formats = Counter(m.get(\"format\", \"Inconnu\") for m in liked_metadata)\n",
    "        orientations = Counter(\n",
    "            \"Portrait\" if m[\"height\"] > m[\"width\"] else \"Paysage\"\n",
    "            for m in liked_metadata if m.get(\"width\") and m.get(\"height\")\n",
    "        )\n",
    "\n",
    "        all_colors = []\n",
    "        all_tags = []\n",
    "        width_total, height_total = 0, 0\n",
    "\n",
    "        for m in liked_metadata:\n",
    "            all_colors.extend(m.get(\"moyenne_couleur_rgb\", []))\n",
    "            all_tags.extend(m.get(\"tags\", []))\n",
    "            width_total += m.get(\"width\", 0)\n",
    "            height_total += m.get(\"height\", 0)\n",
    "\n",
    "        color_counter = Counter(tuple(c) for c in all_colors)\n",
    "        tag_counter = Counter(all_tags)\n",
    "\n",
    "        avg_resolution = {\n",
    "            \"width\": int(width_total / len(liked_metadata)),\n",
    "            \"height\": int(height_total / len(liked_metadata))\n",
    "        }\n",
    "\n",
    "        # Synthèse des préférences de l'utilisateur\n",
    "        user_synthesis = {\n",
    "            \"formats\": dict(formats),\n",
    "            \"orientations\": dict(orientations),\n",
    "            \"top_colors\": color_counter.most_common(10),\n",
    "            \"top_tags\": tag_counter.most_common(10),\n",
    "            \"avg_resolution\": avg_resolution,\n",
    "        }\n",
    "\n",
    "        # Enregistrer la synthèse dans le dictionnaire principal\n",
    "        user_syntheses[user_name] = user_synthesis\n",
    "\n",
    "        export_path = f\"export/analyzed_user_preferences/user_{user_name}_analyzed_preferences.pdf\"\n",
    "        os.makedirs(\"export\", exist_ok=True)\n",
    "\n",
    "        with PdfPages(export_path) as pdf:\n",
    "            create_cover_page(user_name, pdf)\n",
    "            create_table_of_contents(pdf)\n",
    "            visualize_all_results(user_name, color_counter, tag_counter, avg_resolution, formats, orientations, pdf)\n",
    "\n",
    "        print(f\"Rapport PDF généré pour {user_name}: {export_path}\")\n",
    "\n",
    "    # Sauvegarder les synthèses dans un fichier JSON\n",
    "    with open(\"export/user_preferences_summary.json\", \"w\", encoding='utf-8') as f:\n",
    "        json.dump(user_syntheses, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(\"Synthèse des préférences utilisateurs enregistrée dans 'user_preferences_summary.json'.\")\n",
    "\n",
    "\n",
    "def create_cover_page(user_name, pdf):\n",
    "    plt.figure(figsize=(8.5, 11))\n",
    "    plt.text(0.5, 0.7, f\"Rapport des préférences de l'utilisateur {user_name}\", ha='center', va='center', fontsize=20, fontweight=\"bold\")\n",
    "    plt.text(0.5, 0.5, \"Analysées sous forme de graphiques\", ha='center', va='center', fontsize=16)\n",
    "    plt.text(0.5, 0.35, \"Outils utilisés:\", ha='center', va='center', fontsize=14)\n",
    "    plt.text(0.5, 0.2, \"• Matplotlib\", ha='center', va='center', fontsize=12)\n",
    "    plt.text(0.5, 0.15, \"• Seaborn\", ha='center', va='center', fontsize=12)\n",
    "    plt.text(0.5, 0.1, \"• WordCloud\", ha='center', va='center', fontsize=12)\n",
    "    plt.text(0.5, 0.05, \"• Python, JSON, etc.\", ha='center', va='center', fontsize=12)\n",
    "    \n",
    "    plt.axis('off')\n",
    "    pdf.savefig()\n",
    "    plt.show()\n",
    "\n",
    "def create_table_of_contents(pdf):\n",
    "    plt.figure(figsize=(8.5, 11))\n",
    "    plt.text(0.5, 0.9, \"Table des matières\", ha='center', va='center', fontsize=18, fontweight=\"bold\")\n",
    "    \n",
    "    table_of_contents = [\n",
    "        (\"1. Page de garde\", 0.85),\n",
    "        (\"2. Table des matières\", 0.75),\n",
    "        (\"3. Formats d'image préférés\", 0.65),\n",
    "        (\"4. Orientation préférée\", 0.55),\n",
    "        (\"5. Top 10 des couleurs dominantes\", 0.45),\n",
    "        (\"6. Histogramme des couleurs\", 0.35),\n",
    "        (\"7. Nuage de mots des tags\", 0.25),\n",
    "        (\"8. Résolution moyenne des images\", 0.15),\n",
    "    ]\n",
    "    \n",
    "    for item, y_pos in table_of_contents:\n",
    "        plt.text(0.5, y_pos, item, ha='center', va='center', fontsize=14)\n",
    "\n",
    "    plt.axis('off')\n",
    "    pdf.savefig()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_all_results(user_name, color_counter, tag_counter, avg_resolution, formats, orientations, pdf):\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.title(\"Formats d'image préférés\")\n",
    "    plt.bar(formats.keys(), formats.values(), color='skyblue')\n",
    "    plt.xlabel(\"Format\")\n",
    "    plt.ylabel(\"Nombre de likes\")\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.title(\"Orientation préférée\")\n",
    "    plt.bar(orientations.keys(), orientations.values(), color='salmon')\n",
    "    plt.xlabel(\"Orientation\")\n",
    "    plt.ylabel(\"Nombre de likes\")\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    ax = plt.gca()\n",
    "    top_colors = color_counter.most_common(10)\n",
    "    for i, (color, count) in enumerate(top_colors):\n",
    "        hex_color = \"#{:02x}{:02x}{:02x}\".format(*color)\n",
    "        ax.add_patch(Rectangle((i, 0), 1, 1, color=hex_color))\n",
    "        ax.text(i + 0.5, -0.2, f\"{count}\", ha='center', va='top', fontsize=10)\n",
    "        ax.text(i + 0.5, 1.05, hex_color, ha='center', va='bottom', fontsize=8, rotation=45)\n",
    "    ax.set_xlim(0, len(top_colors))\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.axis('off')\n",
    "    plt.title(\"Top 10 couleurs dominantes\")\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    color_labels = [f\"#{r:02x}{g:02x}{b:02x}\" for r, g, b in color_counter.keys()]\n",
    "    plt.bar(range(len(color_counter)), color_counter.values(), color=color_labels)\n",
    "    plt.xlabel(\"Couleurs\")\n",
    "    plt.ylabel(\"Occurrences\")\n",
    "    plt.title(f\"Histogramme des couleurs dominantes de {user_name}\")\n",
    "    plt.xticks([])\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate_from_frequencies(tag_counter)\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Nuage de tags préférés de {user_name}\")\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig()\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    categories = [\"Largeur (px)\", \"Hauteur (px)\"]\n",
    "    values = [avg_resolution[\"width\"], avg_resolution[\"height\"]]\n",
    "    colors = [\"#4682B4\", \"#8B0000\"]\n",
    "    bars = ax.barh(categories, values, color=colors, edgecolor=\"black\", height=0.5)\n",
    "    for bar, value in zip(bars, values):\n",
    "        ax.text(value + 200, bar.get_y() + bar.get_height() / 2, f\"{value} px\", va='center', fontsize=12, fontweight=\"bold\")\n",
    "    ax.set_xlim(0, max(values) * 1.2)\n",
    "    ax.set_xlabel(\"Résolution en pixels\")\n",
    "    ax.set_title(f\"Résolution moyenne des images aimées par {user_name}\")\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    plt.tight_layout()\n",
    "    pdf.savefig()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyser_preferences(\n",
    "        metadata_file=\"export/resultats_metadonnees.json\",\n",
    "        preferences_file=\"export/user_preferences.json\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CALCUL DISTANCE COULEURS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "with open('export/resultats_metadonnees.json', 'r') as f:\n",
    "    images_metadata = json.load(f)\n",
    "\n",
    "with open('export/user_preferences_summary.json', 'r') as f:\n",
    "    user_preferences = json.load(f)\n",
    "\n",
    "def trouver_image_reference(user_name, images_metadata):\n",
    "    # Récupérer les préférences de l'utilisateur\n",
    "    preferences = user_preferences.get(user_name, {})\n",
    "    \n",
    "    # Si l'utilisateur n'a pas de préférences, on retourne une image aléatoire\n",
    "    if not preferences:\n",
    "        print(f\"Aucune préférence trouvée pour l'utilisateur {user_name}, sélection aléatoire d'une image.\")\n",
    "        return random.choice(images_metadata)\n",
    "    \n",
    "    top_colors = [color for color, _ in preferences.get(\"top_colors\", [])]\n",
    "    top_colors_array = np.array(top_colors)\n",
    "    \n",
    "    if top_colors_array.shape[0] > 5:\n",
    "        top_colors_array = top_colors_array[:5] \n",
    "    elif top_colors_array.shape[0] < 5:\n",
    "        top_colors_array = np.tile(top_colors_array, (5 // top_colors_array.shape[0], 1))[:5]\n",
    "\n",
    "    meilleures_distances = []\n",
    "    \n",
    "    for image in images_metadata:\n",
    "        image_rgb = np.array(image[\"moyenne_couleur_rgb\"]).reshape(1, -1)\n",
    "        \n",
    "        distances = euclidean_distances(image_rgb, top_colors_array.reshape(1, -1))  \n",
    "        meilleures_distances.append((image, distances.min()))  \n",
    "    \n",
    "    meilleures_distances.sort(key=lambda x: x[1])\n",
    "    \n",
    "    return meilleures_distances[0][0]\n",
    "\n",
    "def afficher_image_avec_couleurs(image_path, couleurs, titre):\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        fig, ax = plt.subplots(2, 1, gridspec_kw={'height_ratios': [4, 1]}, figsize=(6, 7))\n",
    "\n",
    "        ax[0].imshow(img)\n",
    "        ax[0].set_title(titre)\n",
    "        ax[0].axis('off')\n",
    "\n",
    "        couleurs_array = np.zeros((50, 300, 3))\n",
    "        segment_width = 300 // 5 \n",
    "\n",
    "        for i in range(5):\n",
    "            couleurs_array[:, i * segment_width:(i + 1) * segment_width] = np.array(couleurs[i]) / 255\n",
    "\n",
    "        ax[1].imshow(couleurs_array)\n",
    "        ax[1].set_xticks([])\n",
    "        ax[1].set_yticks([])\n",
    "\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'affichage de l'image {image_path} : {e}\")\n",
    "\n",
    "for user_name in user_preferences.keys():\n",
    "    print(f\"\\nTraitement des préférences pour l'utilisateur {user_name}...\")\n",
    "\n",
    "    image_choisie = trouver_image_reference(user_name, images_metadata)\n",
    "    image_rgb = np.array(image_choisie[\"moyenne_couleur_rgb\"]).reshape(1, -1)\n",
    "    images_rgb = np.array([\n",
    "        np.array(image[\"moyenne_couleur_rgb\"]).flatten() for image in images_metadata\n",
    "    ])\n",
    "\n",
    "    distances = euclidean_distances(image_rgb, images_rgb)\n",
    "    indices_similaires = np.argsort(distances[0])\n",
    "\n",
    "    image_path_choisie = f\"dataset/{image_choisie['nom_fichier']}\"\n",
    "    afficher_image_avec_couleurs(\n",
    "        image_path_choisie,\n",
    "        image_choisie[\"moyenne_couleur_rgb\"],\n",
    "        f\"Image de référence pour {user_name} : {image_choisie['nom_fichier']}\"\n",
    "    )\n",
    "\n",
    "    # Affichage des 5 images similaires\n",
    "    print(f\"Recommandations d'images similaires pour {user_name} :\")\n",
    "    for i in range(1, 6): \n",
    "        image_similaire = images_metadata[indices_similaires[i]]\n",
    "        image_path_similaire = f\"dataset/{image_similaire['nom_fichier']}\"\n",
    "        \n",
    "        couleurs_principales = image_similaire[\"moyenne_couleur_rgb\"]\n",
    "        \n",
    "        titre = f\"{image_similaire['nom_fichier']} (distance={distances[0][indices_similaires[i]]:.2f})\"\n",
    "        afficher_image_avec_couleurs(\n",
    "            image_path_similaire,\n",
    "            couleurs_principales,\n",
    "            titre\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PERCEPTRON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "with open('export/resultats_metadonnees.json', 'r') as f:\n",
    "    images_metadata = json.load(f)\n",
    "\n",
    "with open('export/user_preferences_summary.json', 'r') as f:\n",
    "    user_preferences = json.load(f)\n",
    "\n",
    "def similarité_nom_fichier(nom1, nom2):\n",
    "    return SequenceMatcher(None, nom1, nom2).ratio()\n",
    "\n",
    "def similarité_extension(ext1, ext2):\n",
    "    return 1 if ext1 == ext2 else 0\n",
    "\n",
    "def distance_moyenne_couleurs(couleurs1, couleurs2):\n",
    "    couleurs1 = np.array(couleurs1)\n",
    "    couleurs2 = np.array(couleurs2)\n",
    "    return np.mean(np.linalg.norm(couleurs1 - couleurs2, axis=1))\n",
    "\n",
    "def trouver_image_reference(user_name, images_metadata):\n",
    "    preferences = user_preferences.get(user_name, {})\n",
    "    \n",
    "    # Si l'utilisateur n'a pas de préférences, on retourne une image aléatoire\n",
    "    if not preferences:\n",
    "        print(f\"Aucune préférence trouvée pour l'utilisateur {user_name}, sélection aléatoire d'une image.\")\n",
    "        return random.choice(images_metadata)\n",
    "    \n",
    "    top_colors = [color for color, _ in preferences.get(\"top_colors\", [])]\n",
    "    top_colors_array = np.array(top_colors)\n",
    "    \n",
    "    if top_colors_array.shape[0] > 5:\n",
    "        top_colors_array = top_colors_array[:5]  \n",
    "    elif top_colors_array.shape[0] < 5:\n",
    "        top_colors_array = np.tile(top_colors_array, (5 // top_colors_array.shape[0], 1))[:5]\n",
    "\n",
    "    meilleures_distances = []\n",
    "    \n",
    "    for image in images_metadata:\n",
    "        image_rgb = np.array(image[\"moyenne_couleur_rgb\"]).reshape(1, -1)\n",
    "        distances = euclidean_distances(image_rgb, top_colors_array.reshape(1, -1))  \n",
    "        meilleures_distances.append((image, distances.min())) \n",
    "    \n",
    "    meilleures_distances.sort(key=lambda x: x[1])\n",
    "    \n",
    "    return meilleures_distances[0][0]\n",
    "\n",
    "# Entraînement du modèle \n",
    "X = []\n",
    "y = []\n",
    "\n",
    "models_info = {}\n",
    "\n",
    "for user_name in user_preferences.keys():\n",
    "    print(f\"\\nTraitement des préférences pour l'utilisateur {user_name}...\")\n",
    "\n",
    "    image_choisie = trouver_image_reference(user_name, images_metadata)\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for image in images_metadata:\n",
    "        if image_choisie != image:\n",
    "            features = []\n",
    "\n",
    "            couleur_choisie = np.array(image_choisie[\"moyenne_couleur_rgb\"]).flatten()\n",
    "            couleur_image = np.array(image[\"moyenne_couleur_rgb\"]).flatten()\n",
    "\n",
    "            features.extend(couleur_choisie)\n",
    "            features.extend(couleur_image)\n",
    "\n",
    "            features.append(similarité_nom_fichier(image_choisie[\"nom_fichier\"], image[\"nom_fichier\"]))\n",
    "            features.append(similarité_extension(image_choisie[\"extension\"], image[\"extension\"]))\n",
    "\n",
    "            X.append(features)\n",
    "\n",
    "            distance_couleurs = distance_moyenne_couleurs(\n",
    "                image_choisie[\"moyenne_couleur_rgb\"],\n",
    "                image[\"moyenne_couleur_rgb\"]\n",
    "            )\n",
    "            y.append(1 if distance_couleurs < 150 else 0)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    filtered_metadata = [image for image in images_metadata if image != image_choisie]\n",
    "\n",
    "    X_train, X_test, y_train, y_test, metadata_train, metadata_test = train_test_split(\n",
    "        X_scaled, y, filtered_metadata, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    model = Perceptron(max_iter=1000, eta0=0.1)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Précision du modèle pour {user_name} : {accuracy:.2f}\")\n",
    "\n",
    "    models_info[user_name] = {\n",
    "        \"model\": model,\n",
    "        \"scaler\": scaler,\n",
    "        \"image_choisie\": image_choisie,\n",
    "        \"y_test\": y_test,\n",
    "        \"y_pred\": y_pred,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"metadata_test\": metadata_test,\n",
    "    }\n",
    "\n",
    "\n",
    "for user_name, info in models_info.items():\n",
    "    pdf_filename = f\"export/perceptron/{user_name}_perceptron.pdf\"\n",
    "    with PdfPages(pdf_filename) as pdf:\n",
    "        accuracy = info[\"accuracy\"]\n",
    "        y_pred = info[\"y_pred\"]\n",
    "        image_choisie = info[\"image_choisie\"]\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.text(0.5, 0.8, f\"Recommandations d'images pour {user_name}\", horizontalalignment='center', fontsize=16, weight='bold')\n",
    "        plt.text(0.5, 0.6, f\"Modèle utilisé : Perceptron\", horizontalalignment='center', fontsize=12, style='italic')\n",
    "        plt.text(0.5, 0.4, f\"Précision du modèle : {accuracy:.2f}\", horizontalalignment='center', fontsize=12, weight='bold')\n",
    "        plt.axis('off')\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "\n",
    "        image_path_choisie = f\"dataset/{image_choisie['nom_fichier']}\"\n",
    "        img_choisie = Image.open(image_path_choisie)\n",
    "\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(img_choisie)\n",
    "        plt.title(f\"Image de référence : {image_choisie['nom_fichier']}\")\n",
    "        plt.axis('off')\n",
    "        pdf.savefig() \n",
    "        plt.close()\n",
    "\n",
    "        # Images similaires\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.text(0.5, 0.8, \"Images similaires :\", horizontalalignment='center', fontsize=14, weight='bold')\n",
    "        plt.axis('off')\n",
    "        pdf.savefig() \n",
    "        plt.close()\n",
    "\n",
    "        count = 0\n",
    "        metadata_test = info[\"metadata_test\"]\n",
    "        for i, prediction in enumerate(y_pred):\n",
    "            if prediction == 1 and count < 10:\n",
    "                image_similaire = metadata_test[i]\n",
    "                image_path_similaire = f\"dataset/{image_similaire['nom_fichier']}\"\n",
    "                img_similaire = Image.open(image_path_similaire)\n",
    "\n",
    "                plt.figure(figsize=(6, 6))\n",
    "                plt.imshow(img_similaire)\n",
    "                plt.title(f\"{image_similaire['nom_fichier']}\")\n",
    "                plt.axis('off')\n",
    "                pdf.savefig()  \n",
    "                plt.close()\n",
    "\n",
    "                count += 1\n",
    "\n",
    "    print(f\"Rapport généré pour {user_name} : {pdf_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None \n",
    "\n",
    "# Chargement des métadonnées\n",
    "with open('export/resultats_metadonnees.json', 'r') as f:\n",
    "    images_metadata = json.load(f)\n",
    "\n",
    "with open('export/user_preferences_summary.json', 'r') as f:\n",
    "    user_preferences = json.load(f)\n",
    "\n",
    "# Fonction de similarité\n",
    "def similarité_nom_fichier(nom1, nom2):\n",
    "    return SequenceMatcher(None, nom1, nom2).ratio()\n",
    "\n",
    "def similarité_extension(ext1, ext2):\n",
    "    return 1 if ext1 == ext2 else 0\n",
    "\n",
    "def distance_moyenne_couleurs(couleurs1, couleurs2):\n",
    "    couleurs1 = np.array(couleurs1)\n",
    "    couleurs2 = np.array(couleurs2)\n",
    "    return np.mean(np.linalg.norm(couleurs1 - couleurs2, axis=1))\n",
    "\n",
    "# Trouver l'image de référence basée sur les préférences de l'utilisateur\n",
    "def trouver_image_reference(user_name, images_metadata):\n",
    "    preferences = user_preferences.get(user_name, {})\n",
    "    \n",
    "    if not preferences:\n",
    "        print(f\"Aucune préférence trouvée pour l'utilisateur {user_name}, sélection aléatoire d'une image.\")\n",
    "        return random.choice(images_metadata)\n",
    "    \n",
    "    top_colors = [color for color, _ in preferences.get(\"top_colors\", [])]\n",
    "    top_colors_array = np.array(top_colors)\n",
    "    \n",
    "    if top_colors_array.shape[0] > 5:\n",
    "        top_colors_array = top_colors_array[:5]  \n",
    "    elif top_colors_array.shape[0] < 5:\n",
    "        top_colors_array = np.tile(top_colors_array, (5 // top_colors_array.shape[0], 1))[:5]\n",
    "\n",
    "    meilleures_distances = []\n",
    "    \n",
    "    for image in images_metadata:\n",
    "        image_rgb = np.array(image[\"moyenne_couleur_rgb\"]).reshape(1, -1)\n",
    "        distances = euclidean_distances(image_rgb, top_colors_array.reshape(1, -1))  \n",
    "        meilleures_distances.append((image, distances.min()))  \n",
    "    \n",
    "    meilleures_distances.sort(key=lambda x: x[1])\n",
    "    \n",
    "    return meilleures_distances[0][0]\n",
    "\n",
    "# Entraînement du modèle\n",
    "X = []\n",
    "y = []\n",
    "features_list = []\n",
    "metadata_list = []\n",
    "\n",
    "for user_name in user_preferences.keys():\n",
    "    print(f\"\\nTraitement des préférences pour l'utilisateur {user_name}...\")\n",
    "\n",
    "    image_choisie = trouver_image_reference(user_name, images_metadata)\n",
    "\n",
    "    for image in images_metadata:\n",
    "        if image_choisie != image:\n",
    "            couleur_choisie = np.array(image_choisie[\"moyenne_couleur_rgb\"]).flatten()\n",
    "            couleur_image = np.array(image[\"moyenne_couleur_rgb\"]).flatten()\n",
    "\n",
    "            features = list(couleur_choisie) + list(couleur_image)\n",
    "            features.append(similarité_nom_fichier(image_choisie[\"nom_fichier\"], image[\"nom_fichier\"]))\n",
    "            features.append(similarité_extension(image_choisie[\"extension\"], image[\"extension\"]))\n",
    "\n",
    "            distance_couleurs = distance_moyenne_couleurs(image_choisie[\"moyenne_couleur_rgb\"], image[\"moyenne_couleur_rgb\"])\n",
    "            label = 1 if distance_couleurs < 150 else 0\n",
    "\n",
    "            X.append(features)\n",
    "            y.append(label)\n",
    "            metadata_list.append(image)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test, metadata_train, metadata_test = train_test_split(\n",
    "    X, y, metadata_list, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Création du modèle RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=150, max_depth=20, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Précision du modèle : {accuracy:.2f}\")\n",
    "\n",
    "# Entraînement du modèle pour chaque utilisateur\n",
    "for user_name in user_preferences.keys():\n",
    "    print(f\"\\nTraitement des préférences pour l'utilisateur {user_name}...\")\n",
    "    \n",
    "    X_user = []\n",
    "    y_user = []\n",
    "    metadata_user = []\n",
    "\n",
    "    image_choisie = trouver_image_reference(user_name, images_metadata)\n",
    "\n",
    "    for image in images_metadata:\n",
    "        if image_choisie != image:\n",
    "            couleur_choisie = np.array(image_choisie[\"moyenne_couleur_rgb\"]).flatten()\n",
    "            couleur_image = np.array(image[\"moyenne_couleur_rgb\"]).flatten()\n",
    "\n",
    "            features = list(couleur_choisie) + list(couleur_image)\n",
    "            features.append(similarité_nom_fichier(image_choisie[\"nom_fichier\"], image[\"nom_fichier\"]))\n",
    "            features.append(similarité_extension(image_choisie[\"extension\"], image[\"extension\"]))\n",
    "\n",
    "            distance_couleurs = distance_moyenne_couleurs(image_choisie[\"moyenne_couleur_rgb\"], image[\"moyenne_couleur_rgb\"])\n",
    "            label = 1 if distance_couleurs < 150 else 0\n",
    "\n",
    "            X_user.append(features)\n",
    "            y_user.append(label)\n",
    "            metadata_user.append(image)\n",
    "\n",
    "    X_user = np.array(X_user)\n",
    "    y_user = np.array(y_user)\n",
    "\n",
    "    X_train_user, X_test_user, y_train_user, y_test_user, metadata_train_user, metadata_test_user = train_test_split(\n",
    "        X_user, y_user, metadata_user, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    scaler_user = StandardScaler()\n",
    "    X_train_user_scaled = scaler_user.fit_transform(X_train_user)\n",
    "    X_test_user_scaled = scaler_user.transform(X_test_user)\n",
    "\n",
    "    model_user = RandomForestClassifier(n_estimators=150, max_depth=20, random_state=42, n_jobs=-1)\n",
    "    model_user.fit(X_train_user_scaled, y_train_user)\n",
    "\n",
    "    y_pred_user = model_user.predict(X_test_user_scaled)\n",
    "    accuracy_user = accuracy_score(y_test_user, y_pred_user)\n",
    "    print(f\"Précision du modèle pour {user_name} : {accuracy_user:.2f}\")\n",
    "\n",
    "    pdf_filename = f\"export/randomForestClassifier/{user_name}_randomForestClassifier.pdf\"\n",
    "    with PdfPages(pdf_filename) as pdf:\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.text(0.5, 0.8, f\"Recommandations d'images pour {user_name}\", horizontalalignment='center', fontsize=16, weight='bold')\n",
    "        plt.text(0.5, 0.6, f\"Modèle utilisé : RandomForestClassifier\", horizontalalignment='center', fontsize=12, style='italic')\n",
    "        plt.text(0.5, 0.4, f\"Précision du modèle : {accuracy_user:.2f}\", horizontalalignment='center', fontsize=12, weight='bold') \n",
    "        plt.axis('off')\n",
    "        pdf.savefig()  \n",
    "        plt.close()\n",
    "\n",
    "        image_choisie = trouver_image_reference(user_name, images_metadata)\n",
    "        image_path_choisie = f\"dataset/{image_choisie['nom_fichier']}\"\n",
    "        img_choisie = Image.open(image_path_choisie)\n",
    "\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(img_choisie)\n",
    "        plt.title(f\"Image de référence : {image_choisie['nom_fichier']}\")\n",
    "        plt.axis('off')\n",
    "        pdf.savefig()  \n",
    "        plt.close()\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.text(0.5, 0.8, \"Images similaires :\", horizontalalignment='center', fontsize=14, weight='bold')\n",
    "        plt.axis('off')\n",
    "        pdf.savefig()  \n",
    "        plt.close()\n",
    "\n",
    "        X_test_images_user = []\n",
    "        for image in images_metadata:\n",
    "            if image != image_choisie: \n",
    "                features = []\n",
    "                features.extend(np.array(image_choisie[\"moyenne_couleur_rgb\"]).flatten())\n",
    "                features.extend(np.array(image[\"moyenne_couleur_rgb\"]).flatten())\n",
    "                features.append(similarité_nom_fichier(image_choisie[\"nom_fichier\"], image[\"nom_fichier\"]))\n",
    "                features.append(similarité_extension(image_choisie[\"extension\"], image[\"extension\"]))\n",
    "                X_test_images_user.append(features)\n",
    "\n",
    "        X_test_images_user_scaled = scaler_user.transform(X_test_images_user)\n",
    "\n",
    "        y_pred_images_user = model_user.predict(X_test_images_user_scaled)\n",
    "\n",
    "        count = 0\n",
    "        for i, prediction in enumerate(y_pred_images_user):\n",
    "            if prediction == 1 and count < 10:  \n",
    "                image_similaire = metadata_test_user[i]\n",
    "                image_path_similaire = f\"dataset/{image_similaire['nom_fichier']}\"\n",
    "                if os.path.exists(image_path_similaire):\n",
    "                    img_similaire = Image.open(image_path_similaire)\n",
    "                    plt.figure(figsize=(6, 6))\n",
    "                    plt.imshow(img_similaire)\n",
    "                    plt.title(f\"{image_similaire['nom_fichier']}\")\n",
    "                    plt.axis('off')\n",
    "                    pdf.savefig()  \n",
    "                    plt.close()\n",
    "                    count += 1\n",
    "\n",
    "    print(f\"Rapport généré pour {user_name} : {pdf_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLUSTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "with open('export/resultats_metadonnees.json', 'r') as f:\n",
    "    images_metadata = json.load(f)\n",
    "\n",
    "with open('export/user_preferences_summary.json', 'r') as f:\n",
    "    user_preferences = json.load(f)\n",
    "\n",
    "def similarité_nom_fichier(nom1, nom2):\n",
    "    return SequenceMatcher(None, nom1, nom2).ratio()\n",
    "\n",
    "def similarité_extension(ext1, ext2):\n",
    "    return 1 if ext1 == ext2 else 0\n",
    "\n",
    "def distance_moyenne_couleurs(couleurs1, couleurs2):\n",
    "    couleurs1 = np.array(couleurs1)\n",
    "    couleurs2 = np.array(couleurs2)\n",
    "    return np.mean(np.linalg.norm(couleurs1 - couleurs2, axis=1))\n",
    "\n",
    "def trouver_image_reference(user_name, images_metadata):\n",
    "    preferences = user_preferences.get(user_name, {})\n",
    "    \n",
    "    if not preferences:\n",
    "        print(f\"Aucune préférence trouvée pour l'utilisateur {user_name}, sélection aléatoire d'une image.\")\n",
    "        return random.choice(images_metadata)\n",
    "    \n",
    "    top_colors = [color for color, _ in preferences.get(\"top_colors\", [])]\n",
    "    top_colors_array = np.array(top_colors)\n",
    "    \n",
    "    if top_colors_array.shape[0] > 5:\n",
    "        top_colors_array = top_colors_array[:5]  \n",
    "    elif top_colors_array.shape[0] < 5:\n",
    "        top_colors_array = np.tile(top_colors_array, (5 // top_colors_array.shape[0], 1))[:5]\n",
    "\n",
    "    meilleures_distances = []\n",
    "    \n",
    "    for image in images_metadata:\n",
    "        image_rgb = np.array(image[\"moyenne_couleur_rgb\"]).reshape(1, -1)\n",
    "        \n",
    "        distances = euclidean_distances(image_rgb, top_colors_array.reshape(1, -1))  \n",
    "        meilleures_distances.append((image, distances.min()))  \n",
    "    \n",
    "    meilleures_distances.sort(key=lambda x: x[1])\n",
    "    \n",
    "    return meilleures_distances[0][0]\n",
    "\n",
    "# === Clustering ===\n",
    "# Construction des features\n",
    "X = []\n",
    "image_names = []\n",
    "\n",
    "for image in images_metadata:\n",
    "    features = []\n",
    "    features.extend(np.array(image[\"moyenne_couleur_rgb\"]).flatten())\n",
    "    features.append(len(image[\"nom_fichier\"]))\n",
    "    features.append(similarité_extension(image[\"extension\"], 'jpg'))  \n",
    "    X.append(features)\n",
    "    image_names.append(image[\"nom_fichier\"])\n",
    "\n",
    "X = np.array(X)\n",
    "\n",
    "# Normalisation des features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Réduction de dimension avec PCA\n",
    "pca = PCA(n_components=10)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Clustering avec KMeans\n",
    "n_clusters = 10  \n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_pca)\n",
    "\n",
    "# Ajout des résultats dans les métadonnées\n",
    "for i, image in enumerate(images_metadata):\n",
    "    image['cluster'] = clusters[i]\n",
    "\n",
    "# Regrouper les images par cluster\n",
    "clusters_dict = {i: [] for i in range(n_clusters)}\n",
    "for image in images_metadata:\n",
    "    clusters_dict[image['cluster']].append(image)\n",
    "\n",
    "os.makedirs('export/clusters', exist_ok=True)\n",
    "\n",
    "for user_name in user_preferences.keys():\n",
    "    pdf_filename = f\"export/clusters/{user_name}_clusters.pdf\"\n",
    "    with PdfPages(pdf_filename) as pdf:\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.text(0.5, 0.8, f\"Recommandations d'images pour {user_name}\", horizontalalignment='center', fontsize=16, weight='bold')\n",
    "        plt.text(0.5, 0.6, f\"Utilisation de la méthode des Clusters\", horizontalalignment='center', fontsize=12, style='italic')\n",
    "        plt.axis('off')\n",
    "        pdf.savefig()  \n",
    "        plt.close()\n",
    "\n",
    "        # Graphique en camembert pour les clusters\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        cluster_counts = [0] * n_clusters\n",
    "        for image in images_metadata:\n",
    "            cluster_counts[image['cluster']] += 1\n",
    "        \n",
    "        plt.pie(cluster_counts, labels=[f\"Cluster {i}\" for i in range(n_clusters)], autopct='%1.1f%%', startangle=90)\n",
    "        plt.title(\"Répartition des images par cluster\")\n",
    "        plt.axis('equal')  \n",
    "        pdf.savefig()  \n",
    "        plt.close()\n",
    "\n",
    "        image_choisie = trouver_image_reference(user_name, images_metadata)\n",
    "        image_path_choisie = f\"dataset/{image_choisie['nom_fichier']}\"\n",
    "        img_choisie = Image.open(image_path_choisie)\n",
    "\n",
    "        image_path_choisie = f\"dataset/{image_choisie['nom_fichier']}\"\n",
    "        img_choisie = Image.open(image_path_choisie)\n",
    "        img_choisie.thumbnail((256, 256))\n",
    "\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(img_choisie)\n",
    "        plt.title(f\"Image de référence : {image_choisie['nom_fichier']}\")\n",
    "        plt.axis('off')\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.text(0.5, 0.8, \"Images similaires :\", horizontalalignment='center', fontsize=14, weight='bold')\n",
    "        plt.axis('off')\n",
    "        pdf.savefig()\n",
    "        plt.close()\n",
    "\n",
    "        similar_images = [img for img in clusters_dict[image_choisie['cluster']] if img != image_choisie]\n",
    "\n",
    "        count = 0\n",
    "        for image in similar_images[:10]:  \n",
    "            image_path_similaire = f\"dataset/{image['nom_fichier']}\"\n",
    "            img_similaire = Image.open(image_path_similaire)\n",
    "            img_similaire.thumbnail((256, 256))\n",
    "\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(img_similaire)\n",
    "            plt.title(f\"{image['nom_fichier']}\")\n",
    "            plt.axis('off')\n",
    "            pdf.savefig()\n",
    "            plt.close()\n",
    "\n",
    "            count += 1\n",
    "\n",
    "    print(f\"Rapport généré pour {user_name} : {pdf_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
